{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNoVyE3EVHN72JI6sgtm6Ru",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CreatorGeetansh/Machine-Learning-Projects/blob/main/HandwrittingRecognitionon_MNIST_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DcsbKEQGz1qD"
      },
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiI1eEcQ0UsJ",
        "outputId": "684e8b2c-f5f6-48dd-eeee-c96d8f87c929"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKXhC_bk0uEK",
        "outputId": "1e10ff03-15eb-41b5-d212-c0f99405011c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "vsY3v_3507V0",
        "outputId": "590a7aa3-270a-46d3-ea96-4198d906aa4a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0, 124, 253, 255,  63,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,  96, 244, 251, 253,  62,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 127, 251, 251, 253,  62,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,  68, 236, 251, 211,  31,   8,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  60, 228, 251, 251,  94,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0, 155, 253, 253, 189,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  20, 253, 251, 235,  66,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         32, 205, 253, 251, 126,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        104, 251, 253, 184,  15,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  80,\n",
              "        240, 251, 193,  23,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  32, 253,\n",
              "        253, 253, 159,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 151, 251,\n",
              "        251, 251,  39,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  48, 221, 251,\n",
              "        251, 172,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 234, 251, 251,\n",
              "        196,  12,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 253, 251, 251,\n",
              "         89,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 159, 255, 253, 253,\n",
              "         31,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  48, 228, 253, 247, 140,\n",
              "          8,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  64, 251, 253, 220,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  64, 251, 253, 220,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  24, 193, 253, 220,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ],
            "text/html": [
              "<style>\n",
              "      .ndarray_repr .ndarray_raw_data {\n",
              "        display: none;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_raw_data {\n",
              "        display: block;\n",
              "      }\n",
              "      .ndarray_repr.show_array .ndarray_image_preview {\n",
              "        display: none;\n",
              "      }\n",
              "      </style>\n",
              "      <div id=\"id-54b0dc3b-aab8-4e7c-8900-a11c2c0ee924\" class=\"ndarray_repr\"><pre>ndarray (28, 28) <button style=\"padding: 0 2px;\">show data</button></pre><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAnElEQVR4nGNgGPyg5u9/e1xyCV9+/7WDMJkwJOXZcRvq8ub3ZXkO7HI2T37/jsOlcfbfv3txyYn8/f3aCYecwtm/v+twacz4/XcHPw65gA+/D4rjMvTv37/zcRk6/ffv3+o45Azu/v69BpfGV79/H+HBJfn39+9IXHLz///9K4/Lxid/v/fgCHAGh99/76CLYcYnNskbx/ApoyoAAGeYO0QsY6cRAAAAAElFTkSuQmCC\" class=\"ndarray_image_preview\" /><pre class=\"ndarray_raw_data\">array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0, 124, 253, 255,  63,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,  96, 244, 251, 253,  62,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 127, 251, 251, 253,  62,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,  68, 236, 251, 211,  31,   8,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  60, 228, 251, 251,  94,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0, 155, 253, 253, 189,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  20, 253, 251, 235,  66,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         32, 205, 253, 251, 126,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "        104, 251, 253, 184,  15,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  80,\n",
              "        240, 251, 193,  23,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  32, 253,\n",
              "        253, 253, 159,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 151, 251,\n",
              "        251, 251,  39,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  48, 221, 251,\n",
              "        251, 172,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 234, 251, 251,\n",
              "        196,  12,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 253, 251, 251,\n",
              "         89,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 159, 255, 253, 253,\n",
              "         31,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  48, 228, 253, 247, 140,\n",
              "          8,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  64, 251, 253, 220,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  64, 251, 253, 220,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,  24, 193, 253, 220,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)</pre></div><script>\n",
              "      (() => {\n",
              "      const titles = ['show data', 'hide data'];\n",
              "      let index = 0\n",
              "      document.querySelector('#id-54b0dc3b-aab8-4e7c-8900-a11c2c0ee924 button').onclick = (e) => {\n",
              "        document.querySelector('#id-54b0dc3b-aab8-4e7c-8900-a11c2c0ee924').classList.toggle('show_array');\n",
              "        index = (++index) % 2;\n",
              "        document.querySelector('#id-54b0dc3b-aab8-4e7c-8900-a11c2c0ee924 button').textContent = titles[index];\n",
              "        e.preventDefault();\n",
              "        e.stopPropagation();\n",
              "      }\n",
              "      })();\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(X_train[9])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "vnJWcehm1HF_",
        "outputId": "91dcc925-519e-416c-c85c-4ca1c5df90e2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f4b91ed9870>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NOTE - It is very important in Deep learning to do standardization of data because if data is standardized weights will be calculated faster."
      ],
      "metadata": {
        "id": "gYAWTabl1dI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# now we have values ranges from 0-255 so to standardize divide every value of test and train by 255\n",
        "X_train = X_train/255\n",
        "X_test = X_test/255"
      ],
      "metadata": {
        "id": "DMp0RMV31PNN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDcfmb8-2F4W",
        "outputId": "6c281bdb-2294-45aa-8563-738c8b74c785"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
              "        0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
              "        0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.11764706, 0.14117647,\n",
              "        0.36862745, 0.60392157, 0.66666667, 0.99215686, 0.99215686,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.88235294, 0.6745098 ,\n",
              "        0.99215686, 0.94901961, 0.76470588, 0.25098039, 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.19215686, 0.93333333, 0.99215686,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "        0.99215686, 0.99215686, 0.98431373, 0.36470588, 0.32156863,\n",
              "        0.32156863, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.07058824, 0.85882353, 0.99215686,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.77647059,\n",
              "        0.71372549, 0.96862745, 0.94509804, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.31372549, 0.61176471,\n",
              "        0.41960784, 0.99215686, 0.99215686, 0.80392157, 0.04313725,\n",
              "        0.        , 0.16862745, 0.60392157, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
              "        0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.54509804, 0.99215686, 0.74509804, 0.00784314,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.04313725, 0.74509804, 0.99215686, 0.2745098 ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.1372549 , 0.94509804, 0.88235294,\n",
              "        0.62745098, 0.42352941, 0.00392157, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.31764706, 0.94117647,\n",
              "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
              "        0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.0627451 , 0.36470588, 0.98823529, 0.99215686, 0.73333333,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.97647059, 0.99215686, 0.97647059,\n",
              "        0.25098039, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
              "        0.50980392, 0.71764706, 0.99215686, 0.99215686, 0.81176471,\n",
              "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.15294118, 0.58039216, 0.89803922,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.71372549,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
              "        0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.09019608, 0.25882353,\n",
              "        0.83529412, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
              "        0.77647059, 0.31764706, 0.00784314, 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.07058824, 0.67058824, 0.85882353, 0.99215686,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.76470588, 0.31372549,\n",
              "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.21568627,\n",
              "        0.6745098 , 0.88627451, 0.99215686, 0.99215686, 0.99215686,\n",
              "        0.99215686, 0.95686275, 0.52156863, 0.04313725, 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.53333333,\n",
              "        0.99215686, 0.99215686, 0.99215686, 0.83137255, 0.52941176,\n",
              "        0.51764706, 0.0627451 , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ],\n",
              "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "        0.        , 0.        , 0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Flatten(input_shape = (28,28)))\n",
        "model.add(Dense(128, activation = 'relu'))\n",
        "model.add(Dense(32, activation = 'relu'))\n",
        "model.add(Dense(10, activation = 'softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gyPvcGS2Hyf",
        "outputId": "13924e38-2187-4c9f-ed43-0f71791d7c02"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               100480    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                4128      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 104938 (409.91 KB)\n",
            "Trainable params: 104938 (409.91 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "Ni6g85Lp3TvE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs = 50, validation_split = 0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYGzUMJC3uQA",
        "outputId": "5d48eb65-9f6e-4cfb-b69e-92e95c62b94d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1500/1500 [==============================] - 7s 4ms/step - loss: 0.2937 - accuracy: 0.9147 - val_loss: 0.1788 - val_accuracy: 0.9486\n",
            "Epoch 2/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1247 - accuracy: 0.9630 - val_loss: 0.1300 - val_accuracy: 0.9610\n",
            "Epoch 3/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0860 - accuracy: 0.9745 - val_loss: 0.0973 - val_accuracy: 0.9713\n",
            "Epoch 4/50\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0662 - accuracy: 0.9794 - val_loss: 0.1011 - val_accuracy: 0.9693\n",
            "Epoch 5/50\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0508 - accuracy: 0.9846 - val_loss: 0.1009 - val_accuracy: 0.9692\n",
            "Epoch 6/50\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0431 - accuracy: 0.9859 - val_loss: 0.0964 - val_accuracy: 0.9712\n",
            "Epoch 7/50\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0334 - accuracy: 0.9894 - val_loss: 0.1157 - val_accuracy: 0.9694\n",
            "Epoch 8/50\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0270 - accuracy: 0.9913 - val_loss: 0.0951 - val_accuracy: 0.9730\n",
            "Epoch 9/50\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0231 - accuracy: 0.9928 - val_loss: 0.1030 - val_accuracy: 0.9737\n",
            "Epoch 10/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0213 - accuracy: 0.9933 - val_loss: 0.1115 - val_accuracy: 0.9717\n",
            "Epoch 11/50\n",
            "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0177 - accuracy: 0.9943 - val_loss: 0.1239 - val_accuracy: 0.9697\n",
            "Epoch 12/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0150 - accuracy: 0.9954 - val_loss: 0.1140 - val_accuracy: 0.9753\n",
            "Epoch 13/50\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.1377 - val_accuracy: 0.9719\n",
            "Epoch 14/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0145 - accuracy: 0.9954 - val_loss: 0.1365 - val_accuracy: 0.9718\n",
            "Epoch 15/50\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0131 - accuracy: 0.9953 - val_loss: 0.1308 - val_accuracy: 0.9740\n",
            "Epoch 16/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.1348 - val_accuracy: 0.9718\n",
            "Epoch 17/50\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 0.1248 - val_accuracy: 0.9743\n",
            "Epoch 18/50\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0103 - accuracy: 0.9966 - val_loss: 0.1451 - val_accuracy: 0.9734\n",
            "Epoch 19/50\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 0.1346 - val_accuracy: 0.9740\n",
            "Epoch 20/50\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.1345 - val_accuracy: 0.9762\n",
            "Epoch 21/50\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0078 - accuracy: 0.9978 - val_loss: 0.1574 - val_accuracy: 0.9734\n",
            "Epoch 22/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0114 - accuracy: 0.9965 - val_loss: 0.1531 - val_accuracy: 0.9753\n",
            "Epoch 23/50\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.1487 - val_accuracy: 0.9753\n",
            "Epoch 24/50\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0110 - accuracy: 0.9965 - val_loss: 0.1608 - val_accuracy: 0.9738\n",
            "Epoch 25/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0063 - accuracy: 0.9978 - val_loss: 0.1491 - val_accuracy: 0.9758\n",
            "Epoch 26/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0082 - accuracy: 0.9975 - val_loss: 0.1662 - val_accuracy: 0.9732\n",
            "Epoch 27/50\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.2248 - val_accuracy: 0.9672\n",
            "Epoch 28/50\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.1778 - val_accuracy: 0.9737\n",
            "Epoch 29/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0057 - accuracy: 0.9980 - val_loss: 0.1987 - val_accuracy: 0.9710\n",
            "Epoch 30/50\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.1725 - val_accuracy: 0.9741\n",
            "Epoch 31/50\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0088 - accuracy: 0.9972 - val_loss: 0.1861 - val_accuracy: 0.9747\n",
            "Epoch 32/50\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.1595 - val_accuracy: 0.9750\n",
            "Epoch 33/50\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.1783 - val_accuracy: 0.9757\n",
            "Epoch 34/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0056 - accuracy: 0.9978 - val_loss: 0.1670 - val_accuracy: 0.9749\n",
            "Epoch 35/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0079 - accuracy: 0.9976 - val_loss: 0.1813 - val_accuracy: 0.9747\n",
            "Epoch 36/50\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0067 - accuracy: 0.9976 - val_loss: 0.1791 - val_accuracy: 0.9753\n",
            "Epoch 37/50\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0077 - accuracy: 0.9977 - val_loss: 0.1663 - val_accuracy: 0.9761\n",
            "Epoch 38/50\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.1735 - val_accuracy: 0.9773\n",
            "Epoch 39/50\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.2285 - val_accuracy: 0.9707\n",
            "Epoch 40/50\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0082 - accuracy: 0.9975 - val_loss: 0.1892 - val_accuracy: 0.9759\n",
            "Epoch 41/50\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0046 - accuracy: 0.9982 - val_loss: 0.2024 - val_accuracy: 0.9751\n",
            "Epoch 42/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.2002 - val_accuracy: 0.9760\n",
            "Epoch 43/50\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.1753 - val_accuracy: 0.9768\n",
            "Epoch 44/50\n",
            "1500/1500 [==============================] - 5s 4ms/step - loss: 0.0077 - accuracy: 0.9978 - val_loss: 0.1990 - val_accuracy: 0.9751\n",
            "Epoch 45/50\n",
            "1500/1500 [==============================] - 7s 4ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.2095 - val_accuracy: 0.9741\n",
            "Epoch 46/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.1851 - val_accuracy: 0.9772\n",
            "Epoch 47/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.1865 - val_accuracy: 0.9789\n",
            "Epoch 48/50\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.2293 - val_accuracy: 0.9751\n",
            "Epoch 49/50\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.2054 - val_accuracy: 0.9771\n",
            "Epoch 50/50\n",
            "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.2159 - val_accuracy: 0.9749\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f4b8fd663e0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_prob = model.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rU_HDN6v5Kzm",
        "outputId": "74492bff-06f6-47ab-9264-08fd3b4fbdb3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = y_prob.argmax(axis = 1)"
      ],
      "metadata": {
        "id": "nX68Muv75nvB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(f\"Model's accuracy score: {accuracy_score(y_test, y_pred)*100}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6Stqzqy5zLf",
        "outputId": "b520f12c-acc1-4227-f754-cf2832bb5794"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model's accuracy score: 97.85000000000001%\n"
          ]
        }
      ]
    }
  ]
}